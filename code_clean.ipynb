{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using python 3.6\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import itertools\n",
    "from moviepy.editor import VideoFileClip\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CAMERA CALIBRATION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# camera calibration and distrotion coef\n",
    "# chess board is 9x6 (internal corners)\n",
    "\n",
    "# the object points (stay same) and image point lists\n",
    "rows = 6\n",
    "cols = 9\n",
    "\n",
    "objpts = list(zip(list(range(cols))*rows, \n",
    "             list(itertools.chain(*[[i]*cols for i in range(rows)])), \n",
    "             [0]*rows*cols))\n",
    "# convert from tuple to list to arr \n",
    "objpts = np.array([list(i) for i in objpts], np.float32) \n",
    "objptsLst = []\n",
    "imgptsLst = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform calibration by iterating through calib. images\n",
    "image_files = os.listdir('./camera_cal/')\n",
    "\n",
    "for image_file in image_files:\n",
    "    image_file = './camera_cal/'+image_file # get image path\n",
    "    image = plt.imread(image_file)\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "    # find the image points (chess board corners in that image)\n",
    "    ret, imgpts = cv2.findChessboardCorners(gray, (cols, rows), None)\n",
    "    if ret: # if a valid value has been returned\n",
    "        imgptsLst.append(imgpts)\n",
    "        objptsLst.append(objpts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use img and obj points to find calibration mat and distortion coef\n",
    "ret, mtx, dis, rvecs, tvecs = cv2.calibrateCamera(objptsLst, imgptsLst,\n",
    "                                                 gray.shape[::-1], None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMAGE PROCESSING FUNCTIONS\n",
    "\n",
    "Please note that only some of the functions below are actually used in the final image processing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# undistorts any input image by same camera as above\n",
    "def undistort_img(img, mtx, dis):\n",
    "    return cv2.undistort(img, mtx, dis, None, mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove noise from img using gaussian blurring\n",
    "def gaussian_blur(img, kernel_size):\n",
    "    return cv2.GaussianBlur(img, (kernel_size, kernel_size), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sharpens the edges of image\n",
    "def sharpen(img):\n",
    "    kernel = np.array([[-1,-1,-1,-1,-1],\n",
    "                         [-1,2,2,2,-1],\n",
    "                         [-1,2,16,2,-1],\n",
    "                         [-1,2,2,2,-1],\n",
    "                         [-1,-1,-1,-1,-1]]) / 16.\n",
    "    sharp_img = cv2.filter2D(img, -1, kernel)\n",
    "    return sharp_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply sobel (gradient) thresh\n",
    "def apply_sobel_thresh(img, sobel_kernel=15, gradx_thresh=[0,150], angle_thresh=[0.5,2], show=False):\n",
    "    # convert to grayscale\n",
    "    if len(img.shape) > 2:\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    else: \n",
    "        gray = img\n",
    "    # apply sobel operator\n",
    "    sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # get abs of sobel\n",
    "    sobel_x = np.absolute(sobel_x)\n",
    "    sobel_y = np.absolute(sobel_y)\n",
    "    # get the angel\n",
    "    grad_angle = np.arctan2(sobel_y, sobel_x)\n",
    "    # normalize sobel_x and convert to 8-bit (0 to 255)\n",
    "    max_p = np.max(sobel_x)\n",
    "    sobel_x = np.uint8(255*sobel_x/max_p)\n",
    "    # generate binary image based on thresholds\n",
    "    low_x, high_x = gradx_thresh\n",
    "    low_ang, high_ang = angle_thresh\n",
    "    binary_grad = np.multiply(np.multiply(sobel_x>=low_x, sobel_x<=high_x), \n",
    "                np.multiply(grad_angle>=low_ang, grad_angle<=high_ang))\n",
    "    if show:\n",
    "        plt.imshow(binary_grad, cmap='gray')\n",
    "        plt.show()\n",
    "    \n",
    "    return np.uint8(binary_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply Hue and Saturation thresh\n",
    "# must insert a color img\n",
    "def apply_HS_thresh(img, S_thresh=[100,255], H_thresh=[20,75], show=False):\n",
    "    \n",
    "    # convert to hls image\n",
    "    hls_img = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    # get the channels\n",
    "    H,L,S = hls_img[:,:,0], hls_img[:,:,1], hls_img[:,:,2]\n",
    "    # apply HLS and COLOR thresholds\n",
    "    low_H, high_H = H_thresh\n",
    "    low_S, high_S = S_thresh\n",
    "    binary_hls = np.multiply(np.multiply(H>=low_H, H<=high_H),\n",
    "                    np.multiply(S>=low_S, S<=high_S))\n",
    "    if show:\n",
    "        plt.imshow(binary_hls, cmap='gray')\n",
    "        plt.show()\n",
    "    return np.uint8(binary_hls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply RGB thresh\n",
    "# must insert a color RGB img\n",
    "def apply_RGB_thresh(img, R_thresh=[190,255], G_thresh=[190,255], B_thresh=[190,255], show=False):\n",
    "    \n",
    "    # get the different channels\n",
    "    R,G,B = img[:,:,0], img[:,:,1], img[:,:,2]\n",
    "    # apply COLOR thresholds\n",
    "    low_R, high_R = R_thresh\n",
    "    low_G, high_G = G_thresh\n",
    "    low_B, high_B = B_thresh\n",
    "    binary_rgb = np.multiply(np.multiply(np.multiply(R>=low_R, R<=high_R),\n",
    "                    np.multiply(G>=low_G, G<=high_G)),np.multiply(B>=low_B, B<=high_B))\n",
    "    if show:\n",
    "        plt.imshow(binary_rgb, cmap='gray')\n",
    "        plt.show()\n",
    "    return np.uint8(binary_rgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add threshold images (binary)\n",
    "def add_binary_images(img1, img2):\n",
    "    return np.uint8((img1+img2)>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mask to remove unnecessary points\n",
    "def mask(bit_img):\n",
    "    yy, xx = bit_img.shape[:2]\n",
    "    mask_coords = np.int32([[500,450],[780,450],[1150,yy],[200,yy]])\n",
    "    mask = np.zeros_like(bit_img)\n",
    "    mask = cv2.fillConvexPoly(mask, mask_coords, 255) # we only have one color channel\n",
    "    img_masked = cv2.bitwise_and(bit_img, mask)\n",
    "    return img_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform perspective transform on image\n",
    "def warp(img):\n",
    "    # the source and destination points\n",
    "    # get img dims \n",
    "    h,w = img.shape[:2]\n",
    "    # the source and destination points\n",
    "    src = np.float32([[575,470],[750,470],[260,670],[1100,670]])\n",
    "    dst = np.float32([[200,0],[w-200,0],[200,h],[w-200,h]])\n",
    "    #src = np.float32([[595,450],[690,450],[1040,660],[260,660]])\n",
    "    #dst = np.float32([[300,100],[1060,100],[1060,660],[250,660]])\n",
    "    # get the transformation matrix\n",
    "    M = cv2.getPerspectiveTransform(src, dst)\n",
    "    M_inv = cv2.getPerspectiveTransform(dst, src) # get the inverse transform\n",
    "    warped = cv2.warpPerspective(img, M, \n",
    "            (image.shape[1], image.shape[0]), flags=cv2.INTER_LINEAR)\n",
    "    return warped, M_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sliding windows to detect lanes\n",
    "def sliding_windows(bit_warped, nwinds=9, return_curvature=True):\n",
    "    \n",
    "    # histogram\n",
    "    hist = np.sum(bit_warped[bit_warped.shape[0]//2:,:], axis=0)\n",
    "    #plt.plot(hist)\n",
    "    out_img = np.dstack((bit_warped, bit_warped, bit_warped))*255\n",
    "    \n",
    "    # find the midpoint of x-axis\n",
    "    midpoint = np.int(hist.shape[0]/2)\n",
    "    \n",
    "    # find start of left and right windows\n",
    "    leftx_base = np.argmax(hist[:midpoint])\n",
    "    rightx_base = np.argmax(hist[midpoint:]) + midpoint\n",
    "    window_h = np.int(bit_warped.shape[0]/nwinds)\n",
    "    nonzero_pos = bit_warped.nonzero() \n",
    "    nonzero_y, nonzero_x = nonzero_pos # all the chosen pix (regarless of window)\n",
    "    \n",
    "    # set starting positions\n",
    "    leftx_curr = leftx_base\n",
    "    rightx_curr = rightx_base\n",
    "    # width of the windows\n",
    "    width = 100 # NOTE: var\n",
    "    # threshold to recenter window\n",
    "    pix_thresh = 50 # NOTE: var\n",
    "    # lists to stor inds\n",
    "    left_lane_idx = []\n",
    "    right_lane_idx = []\n",
    "    \n",
    "    for window in range(nwinds):\n",
    "        # starting all the way at the bottom\n",
    "        y_up = bit_warped.shape[0] - (window+1)*window_h\n",
    "        y_down = bit_warped.shape[0] - window*window_h\n",
    "        x_left_l = leftx_curr - width\n",
    "        x_left_r = leftx_curr + width\n",
    "        x_right_l = rightx_curr - width\n",
    "        x_right_r = rightx_curr + width\n",
    "        # draw the windows (first left and then right)\n",
    "        cv2.rectangle(out_img, (x_left_l, y_up), (x_left_r, y_down), (0,255,0), 2)\n",
    "        cv2.rectangle(out_img, (x_right_l, y_up), (x_right_r, y_down), (0,255,0), 2)\n",
    "        # find pixels that are within this window - the 'good' pixels\n",
    "        # the [0] at the end is because the original list is just 1-D arr NOT 2D\n",
    "        good_left = ((nonzero_y < y_down) & (nonzero_y >= y_up) &\\\n",
    "                    (nonzero_x >= x_left_l) & (nonzero_x <= x_left_r)).nonzero()[0]\n",
    "        good_right = ((nonzero_y < y_down) & (nonzero_y >= y_up) &\\\n",
    "                    (nonzero_x >= x_right_l) & (nonzero_x <= x_right_r)).nonzero()[0]\n",
    "        # append them to list\n",
    "        left_lane_idx.append(good_left)\n",
    "        right_lane_idx.append(good_right)\n",
    "        # recenter window (for next iter) if needed\n",
    "        if len(good_left) > pix_thresh:\n",
    "            leftx_curr = np.int(np.mean(nonzero_x[good_left]))\n",
    "        if len(good_right) > pix_thresh:\n",
    "            rightx_curr = np.int(np.mean(nonzero_x[good_right]))\n",
    "        \n",
    "    # concatenate the arrays\n",
    "    left_lane_idx = np.concatenate(left_lane_idx)\n",
    "    right_lane_idx = np.concatenate(right_lane_idx)\n",
    "    # get list of x and y coords\n",
    "    left_x = nonzero_x[left_lane_idx]\n",
    "    left_y = nonzero_y[left_lane_idx]\n",
    "    right_x = nonzero_x[right_lane_idx]\n",
    "    right_y = nonzero_y[right_lane_idx]\n",
    "    # fit a polynomial\n",
    "    left_poly_fit = np.polyfit(left_y, left_x, 2)\n",
    "    right_poly_fit = np.polyfit(right_y, right_x, 2)\n",
    "    \n",
    "    # Generate x and y values of the lanes\n",
    "    ploty = np.linspace(0, bit_warped.shape[0]-1, bit_warped.shape[0] )\n",
    "    left_fitx = left_poly_fit[0]*ploty**2 + \\\n",
    "                left_poly_fit[1]*ploty + left_poly_fit[2]\n",
    "    right_fitx = right_poly_fit[0]*ploty**2 +\\\n",
    "                right_poly_fit[1]*ploty + right_poly_fit[2]\n",
    "    \n",
    "    return_list = [ploty, left_fitx, right_fitx, left_poly_fit, right_poly_fit]\n",
    "    \n",
    "    if return_curvature:\n",
    "        y_ = np.max(ploty)\n",
    "        curvature_left = ((1 + (2*left_poly_fit[0]*y_ + \n",
    "                    left_poly_fit[1])**2)**1.5) / np.absolute(2*left_poly_fit[0])\n",
    "        curvature_right = ((1 + (2*right_poly_fit[0]*y_ + \n",
    "                    right_poly_fit[1])**2)**1.5) / np.absolute(2*right_poly_fit[0])\n",
    "        return_list.append(curvature_left)\n",
    "        return_list.append(curvature_right)\n",
    "        \n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uses previous lane lines to create new lane lines\n",
    "# img is a binary, transformed image\n",
    "def new_lane_lines(img, left_fit, right_fit, margin=100, return_curvature=True):\n",
    "    \n",
    "    # get non-zero points\n",
    "    nonzero = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # make sure points are within margin\n",
    "    left_lane_inds = ((nonzerox > (left_fit[0]*(nonzeroy**2) + left_fit[1]*nonzeroy + \n",
    "    left_fit[2] - margin)) & (nonzerox < (left_fit[0]*(nonzeroy**2) + \n",
    "    left_fit[1]*nonzeroy + left_fit[2] + margin))) \n",
    "\n",
    "    right_lane_inds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + \n",
    "    right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + \n",
    "    right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "    # extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    y_ = np.linspace(0, img.shape[0]-1, img.shape[0] )\n",
    "    left_fitx = left_fit[0]*y_**2 + left_fit[1]*y_ + left_fit[2]\n",
    "    right_fitx = right_fit[0]*y_**2 + right_fit[1]*y_ + right_fit[2]\n",
    "    \n",
    "    return_list = [y_, left_fitx, right_fitx, left_fit, right_fit]\n",
    "    \n",
    "    if return_curvature:\n",
    "        y_ = np.max(y_)\n",
    "        curvature_left = ((1 + (2*left_fit[0]*y_ + \n",
    "                    left_fit[1])**2)**1.5) / np.absolute(2*left_fit[0])\n",
    "        curvature_right = ((1 + (2*right_fit[0]*y_ + \n",
    "                    right_fit[1])**2)**1.5) / np.absolute(2*right_fit[0])\n",
    "        return_list.append(curvature_left)\n",
    "        return_list.append(curvature_right)\n",
    "        \n",
    "    return return_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw lane lines to the original image\n",
    "def draw_lane_lines(orig_img, y_, left_fitx, right_fitx, M_inv):\n",
    "    \n",
    "    h,w = orig_img.shape[:2]\n",
    "    lines_img = np.zeros([h,w]).astype(np.uint8)\n",
    "    color_lines_img = np.dstack([lines_img, lines_img, lines_img])\n",
    "    \n",
    "    # gen points (x,y)\n",
    "    left_pts = np.array([np.transpose(np.vstack([left_fitx, y_]))])\n",
    "    # right lane points in reverse to work with cv2.fillPoly\n",
    "    right_pts = np.array([np.flipud(np.transpose(np.vstack([right_fitx, y_])))])    \n",
    "    all_pts = np.hstack([left_pts, right_pts])\n",
    "    # first add the lines\n",
    "    cv2.polylines(color_lines_img, np.int32(left_pts), isClosed=False, color=[255,0,0], thickness=50)\n",
    "    cv2.polylines(color_lines_img, np.int32(right_pts), isClosed=False, color=[0,0,255], thickness=50)\n",
    "    # now fill the area between the two lanes in green\n",
    "    cv2.fillPoly(color_lines_img, np.int_([all_pts]), (0,255,0))\n",
    "    # unwarp the image\n",
    "    warped_lines = cv2.warpPerspective(color_lines_img, M_inv, (w,h))\n",
    "    # add this to the original image\n",
    "    output_img = cv2.addWeighted(orig_img, 1, warped_lines, 0.3, 0)\n",
    "    \n",
    "    return output_img   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add the curvature of each lane to the image\n",
    "def add_curvature_info(img, left_cur, right_cur):\n",
    "    out = np.copy(img)\n",
    "    cv2.putText(out, 'left curvature: {0:.2f} meters'.format(left_cur), \n",
    "                (50,100), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n",
    "    cv2.putText(out, 'right curvature: {0:.2f} meters'.format(right_cur),\n",
    "                (50,150), cv2.FONT_HERSHEY_SIMPLEX, 1.5, (0,255,0), 2)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Pipeline Function\n",
    "Uses appropriate functions from above to create a pipeline that takes in unmarked road image and returns an image annotated with the lane lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes in original image, performs various functions to generate an output\n",
    "# image with the lane lines detected\n",
    "\n",
    "bad_img_store = []\n",
    "left_fit = [] # blank lists used to test if first image\n",
    "right_fit = []\n",
    "\n",
    "def pipeline(orig_img, mtx=mtx, dis=dis):\n",
    "    \n",
    "    global left_fit, right_fit\n",
    "    \n",
    "    # plot image for checking\n",
    "    #plt.imshow(orig_img)\n",
    "    plt.show()\n",
    "    \n",
    "    try:\n",
    "        # undistort image\n",
    "        undist_img = undistort_img(orig_img, mtx, dis)\n",
    "        # sharpen image\n",
    "        sharpen_img = sharpen(undist_img)\n",
    "        # warp the image\n",
    "        bin_warped_img, M_inv = warp(undist_img)\n",
    "        # apply hls and rgb thresholds\n",
    "        rgb_thresh_img = apply_RGB_thresh(bin_warped_img)\n",
    "        hls_thresh_img = apply_HS_thresh(bin_warped_img)\n",
    "        bin_img = add_binary_images(rgb_thresh_img, hls_thresh_img)\n",
    "        # detect lanes using sliding windows if first image\n",
    "        if len(left_fit)==0 or len(right_fit)==0:\n",
    "            y_, left, right, left_fit, right_fit, cur_left, cur_right =\\\n",
    "            sliding_windows(bin_img, nwinds=9, return_curvature=True)\n",
    "            #print('up')\n",
    "        else: # for rest of the images simple extrapolate using existing lines\n",
    "            y_, left, right, left_fit, right_fit, cur_left, cur_right =\\\n",
    "            new_lane_lines(bin_img, left_fit, right_fit, margin=100, return_curvature=True)\n",
    "            #print('down')\n",
    "            if np.sum(left == right) == len(left):\n",
    "                #print('equal')\n",
    "                y_, left, right, left_fit, right_fit, cur_left, cur_right =\\\n",
    "                sliding_windows(bin_img, nwinds=9, return_curvature=True)\n",
    "                #print('reverted to starting calc again')\n",
    "\n",
    "        # draw the lanes in original image\n",
    "        color_img_lines = draw_lane_lines(orig_img, y_, left, right, M_inv)\n",
    "        # add curvature info\n",
    "        output_img = add_curvature_info(color_img_lines, cur_left, cur_right)\n",
    "        return output_img\n",
    "    \n",
    "    except Exception as e: # capture any errors\n",
    "        print(e)\n",
    "        bad_img_store.append(orig_img)\n",
    "        return orig_img\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annotating the Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] >>>> Building video ./results/lane_lines_video.mp4\n",
      "[MoviePy] Writing video ./results/lane_lines_video.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████▉| 1260/1261 [01:19<00:00, 16.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MoviePy] Done.\n",
      "[MoviePy] >>>> Video ready: ./results/lane_lines_video.mp4 \n",
      "\n",
      "Wall time: 1min 20s\n"
     ]
    }
   ],
   "source": [
    "#### APPLY PIPELINE TO VIDEO ####\n",
    "output_video_file = './results/lane_lines_video.mp4'\n",
    "input_video = VideoFileClip('./project_video.mp4')\n",
    "output_video = input_video.fl_image(pipeline)\n",
    "%time output_video.write_videofile(output_video_file, audio=False) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
